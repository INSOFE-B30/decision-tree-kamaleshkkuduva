---
title: "Decision Trees"
author: "INSOFE Lab Activity on Decision Trees"
date: "23 July 2017"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

# C5.0 Trees

**NOTE** Before starting this assignment please remember to clear your environment, you can do that by running the following code chunk

```{r}
rm(list=ls(all=TRUE))

```

## Goal

* The goal of this activity is to predict wether a patient has liver disease or not based on various patient related attributes


## Agenda 

* Get the data

* Data Pre-processing

* Build a model

* Predictions

* Communication


## Reading & Understanding the Data

### Read the Data

Make sure the dataset is located in your current working directory, or else you can change your working directory using the "setwd()" function.

```{r}
setwd("F:/INSOFE/MachineLearning/Week8/LabDecisionTree")
ilpd_data <- read.csv("ilpd_data.csv")
```

### Understand the data

* Use the str(), summary(), head() and tail() functions to get the dimensions and types of attributes in the dataset

* The dataset has 582 observations and 11 variables

- __The variable descriptions are given below:__

1 - age	 : Age of the patient

2 - gender : Gender of the patient

3 - TB : Total Bilirubin content

4 - DB : Direct Bilirubin content

5 - alk_phos : Alkaline Phosphotase content

6 - alamine : Alamine Aminotransferase content

7 - aspartate : Aspartate Aminotransferase content

8 - TP : Total Protiens content

9 - albumin : 	Albumin content

10 - A/G : Ratio of Albumin and Globulin 

11 - Disease : Whether the patient has liver disease or not 


```{r}
str(ilpd_data)

summary(ilpd_data)

```

```{r}

head(ilpd_data)

tail(ilpd_data)

```


## Data Pre-processing

### Verify Data Integrity

* Verify if the dataset has missing values

```{r}

sum(is.na(ilpd_data))

```

* Verify the data types assigned to the variables in the dataset

```{r}

str(ilpd_data)
# Dependent variable is 'disease' and independent variables are discrete and categorical variables

```

### Split the Data into train and test sets

* Use stratified sampling to split the data into train/test sets (70/30)

* Use the createDataPartition() function from the caret package to do stratified sampling

```{r}

library(caret)

# Set the seed after attaching the caret package

set.seed(007)

# The first argument is the imbalanced class reference variable, the second is the proportion to sample

# Remember to include list = F as the function returns a list otherwise which would not be able to subset a dataframe

trainRows <- createDataPartition(ilpd_data$disease, p = .7, list = F)

train_df <- ilpd_data[trainRows, ]

test_df <- ilpd_data[-trainRows, ]


```

### Impute the missing values

* Impute missing values using knnImputation() function in both the train and test datasets

```{r}

library(DMwR)
train_df <- knnImputation(train_df)
test_df <- knnImputation(test_df)
#Missing values are imputed with knnImputation function
sum(is.na(train_df))
sum(is.na(test_df))

```

## Build a  Decision Tree

### Model the tree

* Use Quinlan's C5.0 decision tree algorithm implementation from the C50 package to build your decision tree

```{r}

library(C50)

c5_entropy <- C5.0(disease ~ . , train_df)

```

* Build a rules based tree

```{r}
# Use the rules = T argument if you want to extract rules later from the model

c5_entropy_rules <- C5.0(disease ~ . , train_df, rules = T)


```

### Variable Importance in trees

* Find the importance of each variable in the dataset

```{r}

C5imp(c5_entropy, metric = "usage")

```

### Rules from trees

* Understand the summary of the returned c5.0 rules based on the decision tree model


```{r}

summary(c5_entropy_rules)

```


### Plotting the tree

* Call the plot function on the tree object to visualize the tree

```{r, fig.width= 35, fig.height=15}

plot(c5_entropy)

```


## Evaluating the model

### Predictions on the test data

* Evaluate the decision tree using the standard error metrics on test data

```{r}

predicted <- predict(c5_entropy, test_df)

```

* Report error metrics for classification on test data

```{r}

library(caret)
library(e1071)

confusionMatrix(predicted, test_df$disease)

```

# CART Trees

**NOTE** Before starting this assignment please remember to clear your environment, you can do that by running the following code chunk

```{r}

rm(list=ls(all=TRUE))

```

* The classification and regression trees use gini index in place of the gain ratio (based on information gain) used by the ID3 based algorithms, such as c4.5 and c5.0

## Goal

* The goal of this activity is to predict the heating load of a residential building, if the building parameters are given

* Hence, in the future architects would be able to build more energy efficient buildings as they can optimize the building parameters to reduce the heating load

## Agenda 

* Get the data

* Data Pre-processing

* Build a model

* Predictions

* Communication


## Reading & Understanding the Data

### Read the Data

* Make sure the dataset is located in your current working directory, or else you can change your working directory using the "setwd()" function.

```{r}

setwd("F:/INSOFE/MachineLearning/Week8/LabDecisionTree")
energy_data <- read.csv("building_energy.csv", na.strings = "")

```

### Understand the data

* Use the str(), summary(), head() and tail() functions to get the dimensions and types of attributes in the dataset

* The dataset has 768 observations and 9 variables

```{r}

str(energy_data)
summary(energy_data)
head(energy_data)
tail(energy_data)

```

* The variable names are self explanatory, for further information visit http://www.sciencedirect.com/science/article/pii/S037877881200151X

## Data Pre-processing

### Verify Data Integrity

* Verify if the dataset has missing values

```{r}

sum(is.na(energy_data))

```

* Verify the data types assigned to the variables in the dataset

```{r}

# Enter answer here

str(energy_data)

```

### Split the Data

* Split the data into train/test sets (70/30)

```{r}

set.seed(123)

train_rows <- sample(1:nrow(energy_data), 0.7*nrow(energy_data))

train_cart <- energy_data[train_rows, ]

test_cart <- energy_data[-train_rows, ]

```

## Build a Regression Tree

### Model the tree

* Use the rpart package to build a cart tree to predict the heating load

```{r}

library(rpart)

cart_gini <- rpart(heating_load ~ ., train_cart)

printcp(cart_gini)

```

### Tree Explicability

* Print the variable importance

```{r}

cart_gini$variable.importance


```

* Plot the regression tree

```{r, fig.width=8, fig.height=5}

library(rpart.plot)
library(RColorBrewer)
#fancyRpartPlot(cart_gini)
rpart.plot(cart_gini)

```

## Evaluation on Test Data

* Report error metrics on the test data

```{r}
predicted_cart <- predict(cart_gini, test_cart)


```

```{r}

library(DMwR)

regr.eval(test_cart$heating_load, predicted_cart)


```




















